# simple_gpt_model

This is a simple generative pre-trained transformer model with self-attention. The optimization methods used are Layer Normalization and Residual connections. 
